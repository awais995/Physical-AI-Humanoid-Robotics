"use strict";(globalThis.webpackChunkphysical_ai_humanoid_book=globalThis.webpackChunkphysical_ai_humanoid_book||[]).push([[97],{7747:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>t,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real","title":"Chapter 4: Sim-to-Real Transfer","description":"This chapter covers the techniques and methodologies for transferring models and behaviors trained in simulation to real-world humanoid robots using NVIDIA Isaac platforms.","source":"@site/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real.md","sourceDirName":"module3/NVIDIA-Isaac-AI-Robot-Brain","slug":"/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real","permalink":"/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Nav2 for Bipedal Path Planning","permalink":"/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter3-nav2-bipedal"},"next":{"title":"Module 4: Vision-Language-Action (VLA) + Capstone","permalink":"/docs/module4/Vision-Language-Action-VLA/"}}');var r=a(4848),s=a(8453);const t={sidebar_position:7},o="Chapter 4: Sim-to-Real Transfer",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Sim-to-Real Transfer",id:"introduction-to-sim-to-real-transfer",level:2},{value:"Domain Randomization Techniques",id:"domain-randomization-techniques",level:2},{value:"Visual Domain Randomization",id:"visual-domain-randomization",level:3},{value:"Physics Domain Randomization",id:"physics-domain-randomization",level:3},{value:"Domain Adaptation Methods",id:"domain-adaptation-methods",level:2},{value:"Unsupervised Domain Adaptation",id:"unsupervised-domain-adaptation",level:3},{value:"Fine-Tuning Approaches",id:"fine-tuning-approaches",level:3},{value:"Validation and Testing Strategies",id:"validation-and-testing-strategies",level:2},{value:"Simulation Fidelity Assessment",id:"simulation-fidelity-assessment",level:3},{value:"Transfer Learning for Humanoid Control",id:"transfer-learning-for-humanoid-control",level:2},{value:"Reinforcement Learning Transfer",id:"reinforcement-learning-transfer",level:3},{value:"Best Practices for Sim-to-Real Transfer",id:"best-practices-for-sim-to-real-transfer",level:2},{value:"Systematic Approach",id:"systematic-approach",level:3},{value:"Common Pitfalls to Avoid",id:"common-pitfalls-to-avoid",level:3},{value:"Research Tasks",id:"research-tasks",level:2},{value:"Evidence Requirements",id:"evidence-requirements",level:2},{value:"References",id:"references",level:2},{value:"Practical Exercises",id:"practical-exercises",level:2}];function m(n){const e={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"chapter-4-sim-to-real-transfer",children:"Chapter 4: Sim-to-Real Transfer"})}),"\n",(0,r.jsx)(e.p,{children:"This chapter covers the techniques and methodologies for transferring models and behaviors trained in simulation to real-world humanoid robots using NVIDIA Isaac platforms."}),"\n",(0,r.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(e.p,{children:"After completing this chapter, students will be able to:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Understand the challenges and solutions in sim-to-real transfer for humanoid robotics"}),"\n",(0,r.jsx)(e.li,{children:"Implement domain randomization and domain adaptation techniques"}),"\n",(0,r.jsx)(e.li,{children:"Validate simulation models against real-world performance"}),"\n",(0,r.jsx)(e.li,{children:"Apply transfer learning methods to adapt simulation-trained models for real robots"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"introduction-to-sim-to-real-transfer",children:"Introduction to Sim-to-Real Transfer"}),"\n",(0,r.jsx)(e.p,{children:'Sim-to-real transfer is the process of taking models, policies, or behaviors trained in simulation and successfully deploying them on real robots. This approach is essential for humanoid robotics due to the high cost and complexity of real-world training. However, the "reality gap" between simulation and real-world conditions presents significant challenges.'}),"\n",(0,r.jsx)(e.p,{children:"The reality gap encompasses differences in:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Visual appearance (textures, lighting, camera noise)"}),"\n",(0,r.jsx)(e.li,{children:"Physics properties (friction, mass, dynamics)"}),"\n",(0,r.jsx)(e.li,{children:"Sensor characteristics (noise, latency, resolution)"}),"\n",(0,r.jsx)(e.li,{children:"Environmental conditions (air resistance, vibrations)"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"[@peng2018; @tobin2017]"}),"\n",(0,r.jsx)(e.h2,{id:"domain-randomization-techniques",children:"Domain Randomization Techniques"}),"\n",(0,r.jsx)(e.p,{children:"Domain randomization is a key technique for improving sim-to-real transfer by training models on highly varied simulation environments."}),"\n",(0,r.jsx)(e.h3,{id:"visual-domain-randomization",children:"Visual Domain Randomization"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Implementing visual domain randomization in Isaac Sim\nimport omni\nimport numpy as np\nfrom pxr import UsdShade, Gf, Sdf\n\nclass VisualDomainRandomizer:\n    def __init__(self):\n        self.visual_params = {\n            'lighting': {\n                'intensity_range': (100, 1000),\n                'color_range': (0.5, 1.0),\n                'position_range': (-10, 10)\n            },\n            'material_properties': {\n                'albedo_range': (0.0, 1.0),\n                'roughness_range': (0.0, 1.0),\n                'metallic_range': (0.0, 0.5),\n                'normal_map_strength': (0.0, 1.0)\n            },\n            'camera_noise': {\n                'gaussian_noise_std': (0.0, 0.1),\n                'motion_blur_range': (0.0, 0.5),\n                'color_aberration_range': (0.0, 0.1)\n            }\n        }\n\n    def randomize_lighting(self):\n        \"\"\"Randomize lighting conditions in the simulation\"\"\"\n        # Get all lights in the scene\n        lights = self.get_all_lights()\n\n        for light in lights:\n            # Randomize intensity\n            intensity = np.random.uniform(\n                self.visual_params['lighting']['intensity_range'][0],\n                self.visual_params['lighting']['intensity_range'][1]\n            )\n            light.GetIntensityAttr().Set(intensity)\n\n            # Randomize color\n            color = Gf.Vec3f(\n                np.random.uniform(\n                    self.visual_params['lighting']['color_range'][0],\n                    self.visual_params['lighting']['color_range'][1]\n                ),\n                np.random.uniform(\n                    self.visual_params['lighting']['color_range'][0],\n                    self.visual_params['lighting']['color_range'][1]\n                ),\n                np.random.uniform(\n                    self.visual_params['lighting']['color_range'][0],\n                    self.visual_params['lighting']['color_range'][1]\n                )\n            )\n            light.GetColorAttr().Set(color)\n\n            # Randomize position\n            position = [\n                np.random.uniform(\n                    self.visual_params['lighting']['position_range'][0],\n                    self.visual_params['lighting']['position_range'][1]\n                ) for _ in range(3)\n            ]\n            light.GetPrim().GetAttribute(\"xformOp:translate\").Set(position)\n\n    def randomize_materials(self):\n        \"\"\"Randomize material properties for domain transfer\"\"\"\n        # Iterate through all materials in the scene\n        materials = self.get_all_materials()\n\n        for material_prim in materials:\n            shader = UsdShade.Shader(material_prim)\n\n            # Randomize albedo/diffuse color\n            albedo = Gf.Vec3f(\n                np.random.uniform(\n                    self.visual_params['material_properties']['albedo_range'][0],\n                    self.visual_params['material_properties']['albedo_range'][1]\n                ) for _ in range(3)\n            )\n            shader.GetInput(\"diffuse_color\").Set(albedo)\n\n            # Randomize roughness\n            roughness = np.random.uniform(\n                self.visual_params['material_properties']['roughness_range'][0],\n                self.visual_params['material_properties']['roughness_range'][1]\n            )\n            shader.GetInput(\"roughness\").Set(roughness)\n\n            # Randomize metallic properties\n            metallic = np.random.uniform(\n                self.visual_params['material_properties']['metallic_range'][0],\n                self.visual_params['material_properties']['metallic_range'][1]\n            )\n            shader.GetInput(\"metallic\").Set(metallic)\n\n    def add_camera_noise(self, camera):\n        \"\"\"Add realistic noise to camera sensors\"\"\"\n        # Simulate Gaussian noise\n        gaussian_noise_std = np.random.uniform(\n            self.visual_params['camera_noise']['gaussian_noise_std'][0],\n            self.visual_params['camera_noise']['gaussian_noise_std'][1]\n        )\n\n        # Apply noise characteristics to camera\n        # This would typically involve post-processing in the rendering pipeline\n        pass\n"})}),"\n",(0,r.jsx)(e.p,{children:"[@tobin2017; @lakshmanan2021]"}),"\n",(0,r.jsx)(e.h3,{id:"physics-domain-randomization",children:"Physics Domain Randomization"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Physics domain randomization for humanoid dynamics\nclass PhysicsDomainRandomizer:\n    def __init__(self):\n        self.physics_params = {\n            'dynamics': {\n                'mass_multiplier_range': (0.8, 1.2),\n                'friction_range': (0.1, 1.0),\n                'restitution_range': (0.0, 0.5),\n                'damping_range': (0.01, 0.1)\n            },\n            'actuator_noise': {\n                'control_noise_std': (0.001, 0.01),\n                'delay_range': (0.0, 0.05),\n                'bias_range': (-0.01, 0.01)\n            },\n            'environmental_effects': {\n                'air_resistance_range': (0.0, 0.1),\n                'external_force_range': (-5.0, 5.0),\n                'vibration_frequency_range': (0.1, 10.0)\n            }\n        }\n\n    def randomize_dynamics(self, robot):\n        \"\"\"Randomize physical properties of the robot\"\"\"\n        for link in robot.get_links():\n            # Randomize mass\n            original_mass = link.get_mass()\n            mass_multiplier = np.random.uniform(\n                self.physics_params['dynamics']['mass_multiplier_range'][0],\n                self.physics_params['dynamics']['mass_multiplier_range'][1]\n            )\n            new_mass = original_mass * mass_multiplier\n            link.set_mass(new_mass)\n\n            # Randomize friction\n            friction = np.random.uniform(\n                self.physics_params['dynamics']['friction_range'][0],\n                self.physics_params['dynamics']['friction_range'][1]\n            )\n            link.set_friction(friction)\n\n            # Randomize restitution (bounciness)\n            restitution = np.random.uniform(\n                self.physics_params['dynamics']['restitution_range'][0],\n                self.physics_params['dynamics']['restitution_range'][1]\n            )\n            link.set_restitution(restitution)\n\n            # Randomize damping\n            linear_damping = np.random.uniform(\n                self.physics_params['dynamics']['damping_range'][0],\n                self.physics_params['dynamics']['damping_range'][1]\n            )\n            angular_damping = np.random.uniform(\n                self.physics_params['dynamics']['damping_range'][0],\n                self.physics_params['dynamics']['damping_range'][1]\n            )\n            link.set_linear_damping(linear_damping)\n            link.set_angular_damping(angular_damping)\n\n    def add_actuator_noise(self, actuators):\n        \"\"\"Add realistic noise to actuators\"\"\"\n        for actuator in actuators:\n            # Add control noise\n            control_noise_std = np.random.uniform(\n                self.physics_params['actuator_noise']['control_noise_std'][0],\n                self.physics_params['actuator_noise']['control_noise_std'][1]\n            )\n            actuator.set_control_noise_std(control_noise_std)\n\n            # Add delay\n            delay = np.random.uniform(\n                self.physics_params['actuator_noise']['delay_range'][0],\n                self.physics_params['actuator_noise']['delay_range'][1]\n            )\n            actuator.set_delay(delay)\n\n            # Add bias\n            bias = np.random.uniform(\n                self.physics_params['actuator_noise']['bias_range'][0],\n                self.physics_params['actuator_noise']['bias_range'][1]\n            )\n            actuator.set_bias(bias)\n\n    def simulate_environmental_effects(self, world):\n        \"\"\"Simulate environmental effects that affect real robots\"\"\"\n        # Add air resistance\n        air_resistance = np.random.uniform(\n            self.physics_params['environmental_effects']['air_resistance_range'][0],\n            self.physics_params['environmental_effects']['air_resistance_range'][1]\n        )\n\n        # Add external forces (simulating wind, vibrations)\n        external_force = [\n            np.random.uniform(\n                self.physics_params['environmental_effects']['external_force_range'][0],\n                self.physics_params['environmental_effects']['external_force_range'][1]\n            ) for _ in range(3)\n        ]\n\n        # Add vibrations\n        vibration_freq = np.random.uniform(\n            self.physics_params['environmental_effects']['vibration_frequency_range'][0],\n            self.physics_params['environmental_effects']['vibration_frequency_range'][1]\n        )\n\n        # Apply these effects to the simulation\n        self.apply_effects_to_world(world, air_resistance, external_force, vibration_freq)\n"})}),"\n",(0,r.jsx)(e.p,{children:"[@peng2018; @michel2018]"}),"\n",(0,r.jsx)(e.h2,{id:"domain-adaptation-methods",children:"Domain Adaptation Methods"}),"\n",(0,r.jsx)(e.p,{children:"Domain adaptation involves adapting models trained in simulation to work better in the real world using limited real-world data."}),"\n",(0,r.jsx)(e.h3,{id:"unsupervised-domain-adaptation",children:"Unsupervised Domain Adaptation"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# Unsupervised domain adaptation for perception models\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nclass DomainAdaptationNetwork(nn.Module):\n    def __init__(self, num_classes=5):\n        super(DomainAdaptationNetwork, self).__init__()\n\n        # Feature extractor (shared between domains)\n        self.feature_extractor = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.AdaptiveAvgPool2d((8, 8))\n        )\n\n        # Label classifier (task-specific)\n        self.label_classifier = nn.Sequential(\n            nn.Linear(128 * 8 * 8, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n\n        # Domain classifier (domain-specific)\n        self.domain_classifier = nn.Sequential(\n            nn.Linear(128 * 8 * 8, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(512, 2)  # 2 domains: sim and real\n        )\n\n    def forward(self, x, alpha=0.0):\n        # Extract features\n        features = self.feature_extractor(x)\n        features = features.view(features.size(0), -1)\n\n        # Reverse gradient for domain adaptation\n        reverse_features = ReverseLayerF.apply(features, alpha)\n\n        # Get predictions\n        label_preds = self.label_classifier(features)\n        domain_preds = self.domain_classifier(reverse_features)\n\n        return label_preds, domain_preds\n\nclass ReverseLayerF(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x, alpha):\n        ctx.alpha = alpha\n        return x.view_as(x)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        output = grad_output.neg() * ctx.alpha\n        return output, None\n\ndef train_domain_adaptation(model, sim_loader, real_loader, num_epochs=100):\n    """Train model with domain adaptation"""\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion_label = nn.CrossEntropyLoss()\n    criterion_domain = nn.CrossEntropyLoss()\n\n    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")\n    model.to(device)\n\n    for epoch in range(num_epochs):\n        # Training loop with both simulation and real data\n        for (sim_data, sim_labels), (real_data, _) in zip(sim_loader, real_loader):\n            # Prepare data\n            sim_data, sim_labels = sim_data.to(device), sim_labels.to(device)\n            real_data = real_data.to(device)\n\n            # Combine data\n            combined_data = torch.cat((sim_data, real_data), dim=0)\n            domain_labels = torch.cat(\n                (torch.zeros(sim_data.size(0)), torch.ones(real_data.size(0))),\n                dim=0\n            ).long().to(device)\n\n            # Compute alpha for gradient reversal\n            p = float(epoch * len(sim_loader)) / num_epochs / len(sim_loader)\n            alpha = 2. / (1. + np.exp(-10 * p)) - 1\n\n            # Forward pass\n            label_preds, domain_preds = model(combined_data, alpha)\n\n            # Compute losses\n            sim_label_loss = criterion_label(\n                label_preds[:sim_data.size(0)],\n                sim_labels\n            )\n            domain_loss = criterion_domain(domain_preds, domain_labels)\n\n            total_loss = sim_label_loss + domain_loss\n\n            # Backward pass\n            optimizer.zero_grad()\n            total_loss.backward()\n            optimizer.step()\n'})}),"\n",(0,r.jsx)(e.p,{children:"[@ganin2016; @tzeng2017]"}),"\n",(0,r.jsx)(e.h3,{id:"fine-tuning-approaches",children:"Fine-Tuning Approaches"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# Fine-tuning simulation-trained models with real data\nclass ModelFineTuner:\n    def __init__(self, pretrained_model):\n        self.pretrained_model = pretrained_model\n        self.original_model = pretrained_model.state_dict()\n\n    def fine_tune_with_real_data(self, real_dataset, learning_rate=1e-5, epochs=10):\n        """Fine-tune model with limited real-world data"""\n        # Load pretrained model\n        model = self.pretrained_model\n        model.train()\n\n        # Use a lower learning rate for fine-tuning\n        optimizer = torch.optim.Adam(\n            model.parameters(),\n            lr=learning_rate,\n            weight_decay=1e-4\n        )\n\n        criterion = nn.CrossEntropyLoss()\n        real_loader = DataLoader(real_dataset, batch_size=16, shuffle=True)\n\n        for epoch in range(epochs):\n            total_loss = 0.0\n            for batch_idx, (data, target) in enumerate(real_loader):\n                optimizer.zero_grad()\n\n                output = model(data)\n                loss = criterion(output, target)\n\n                loss.backward()\n\n                # Gradient clipping to prevent overfitting to small real dataset\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n                optimizer.step()\n\n                total_loss += loss.item()\n\n                if batch_idx % 10 == 0:\n                    print(f\'Fine-tuning Epoch: {epoch}, Batch: {batch_idx}, \'\n                          f\'Loss: {loss.item():.6f}\')\n\n        return model\n\n    def gradual_layer_unfreezing(self, real_dataset, epochs_per_stage=5):\n        """Gradually unfreeze layers starting from the top"""\n        model = self.pretrained_model\n\n        # Get all named parameters\n        named_params = list(model.named_parameters())\n\n        # Freeze all layers initially\n        for name, param in named_params:\n            param.requires_grad = False\n\n        # Unfreeze and train layers gradually from top to bottom\n        for i, (name, param) in enumerate(reversed(named_params)):\n            print(f"Unfreezing layer: {name}")\n            param.requires_grad = True\n\n            # Train for a few epochs with this layer unfrozen\n            optimizer = torch.optim.Adam(\n                filter(lambda p: p.requires_grad, model.parameters()),\n                lr=1e-5\n            )\n\n            criterion = nn.CrossEntropyLoss()\n            real_loader = DataLoader(real_dataset, batch_size=16, shuffle=True)\n\n            for epoch in range(epochs_per_stage):\n                for data, target in real_loader:\n                    optimizer.zero_grad()\n\n                    output = model(data)\n                    loss = criterion(output, target)\n\n                    loss.backward()\n                    optimizer.step()\n\n        return model\n'})}),"\n",(0,r.jsx)(e.p,{children:"[@yosinski2014; @donahue2014]"}),"\n",(0,r.jsx)(e.h2,{id:"validation-and-testing-strategies",children:"Validation and Testing Strategies"}),"\n",(0,r.jsx)(e.h3,{id:"simulation-fidelity-assessment",children:"Simulation Fidelity Assessment"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# Assessing simulation fidelity against real-world performance\nclass SimulationFidelityAssessor:\n    def __init__(self):\n        self.metrics = {\n            \'kinematic_accuracy\': [],\n            \'dynamic_accuracy\': [],\n            \'sensor_fidelity\': [],\n            \'behavior_similarity\': []\n        }\n\n    def assess_kinematic_fidelity(self, sim_robot, real_robot, test_trajectories):\n        """Compare kinematic behavior between sim and real"""\n        sim_positions = []\n        real_positions = []\n\n        for trajectory in test_trajectories:\n            # Execute trajectory in simulation\n            sim_pos = self.execute_trajectory(sim_robot, trajectory)\n            sim_positions.extend(sim_pos)\n\n            # Execute same trajectory on real robot\n            real_pos = self.execute_trajectory(real_robot, trajectory)\n            real_positions.extend(real_pos)\n\n        # Calculate kinematic similarity\n        kinematic_error = self.calculate_position_error(sim_positions, real_positions)\n        self.metrics[\'kinematic_accuracy\'].append(kinematic_error)\n\n        return kinematic_error\n\n    def assess_dynamic_fidelity(self, sim_robot, real_robot, test_commands):\n        """Compare dynamic response between sim and real"""\n        sim_responses = []\n        real_responses = []\n\n        for command in test_commands:\n            # Apply command to simulation\n            sim_response = self.apply_command_and_measure(sim_robot, command)\n            sim_responses.append(sim_response)\n\n            # Apply same command to real robot\n            real_response = self.apply_command_and_measure(real_robot, command)\n            real_responses.append(real_response)\n\n        # Calculate dynamic similarity\n        dynamic_error = self.calculate_dynamic_error(sim_responses, real_responses)\n        self.metrics[\'dynamic_accuracy\'].append(dynamic_error)\n\n        return dynamic_error\n\n    def assess_sensor_fidelity(self, sim_sensors, real_sensors, test_scenarios):\n        """Compare sensor outputs between sim and real"""\n        sim_sensor_data = []\n        real_sensor_data = []\n\n        for scenario in test_scenarios:\n            # Collect sensor data in simulation\n            sim_data = self.collect_sensor_data(sim_sensors, scenario)\n            sim_sensor_data.append(sim_data)\n\n            # Collect sensor data on real robot\n            real_data = self.collect_sensor_data(real_sensors, scenario)\n            real_sensor_data.append(real_data)\n\n        # Calculate sensor fidelity\n        sensor_fidelity = self.calculate_sensor_similarity(\n            sim_sensor_data,\n            real_sensor_data\n        )\n        self.metrics[\'sensor_fidelity\'].append(sensor_fidelity)\n\n        return sensor_fidelity\n\n    def calculate_position_error(self, sim_positions, real_positions):\n        """Calculate position error between sim and real"""\n        if len(sim_positions) != len(real_positions):\n            raise ValueError("Position sequences must have same length")\n\n        errors = []\n        for sim_pos, real_pos in zip(sim_positions, real_positions):\n            error = np.linalg.norm(np.array(sim_pos) - np.array(real_pos))\n            errors.append(error)\n\n        return np.mean(errors)\n\n    def calculate_dynamic_error(self, sim_responses, real_responses):\n        """Calculate dynamic response error"""\n        errors = []\n        for sim_resp, real_resp in zip(sim_responses, real_responses):\n            # Compare response characteristics (rise time, settling time, etc.)\n            response_error = self.compare_response_characteristics(\n                sim_resp,\n                real_resp\n            )\n            errors.append(response_error)\n\n        return np.mean(errors)\n\n    def calculate_sensor_similarity(self, sim_data, real_data):\n        """Calculate similarity between sensor data"""\n        similarities = []\n        for sim_datum, real_datum in zip(sim_data, real_data):\n            # Use appropriate similarity metric based on sensor type\n            if isinstance(sim_datum, np.ndarray) and isinstance(real_datum, np.ndarray):\n                # For image data, use SSIM or other image similarity metrics\n                similarity = self.calculate_image_similarity(sim_datum, real_datum)\n            else:\n                # For other data types, use correlation or other metrics\n                similarity = self.calculate_data_similarity(sim_datum, real_datum)\n\n            similarities.append(similarity)\n\n        return np.mean(similarities)\n\n    def calculate_image_similarity(self, sim_img, real_img):\n        """Calculate image similarity (e.g., SSIM)"""\n        from skimage.metrics import structural_similarity as ssim\n\n        # Ensure images are in the right format\n        sim_img = (sim_img * 255).astype(np.uint8)\n        real_img = (real_img * 255).astype(np.uint8)\n\n        similarity = ssim(sim_img, real_img, multichannel=True)\n        return similarity\n\n    def aggregate_fidelity_metrics(self):\n        """Aggregate all fidelity metrics into a single score"""\n        # Weighted average of all metrics\n        weights = {\n            \'kinematic_accuracy\': 0.3,\n            \'dynamic_accuracy\': 0.3,\n            \'sensor_fidelity\': 0.25,\n            \'behavior_similarity\': 0.15\n        }\n\n        weighted_score = 0.0\n        for metric_name, weight in weights.items():\n            if self.metrics[metric_name]:\n                # Normalize the error (lower error = higher fidelity)\n                avg_error = np.mean(self.metrics[metric_name])\n                fidelity_score = 1.0 / (1.0 + avg_error)  # Convert error to fidelity\n                weighted_score += weight * fidelity_score\n\n        return weighted_score\n'})}),"\n",(0,r.jsx)(e.p,{children:"[@koenemann2015; @sadeghi2016]"}),"\n",(0,r.jsx)(e.h2,{id:"transfer-learning-for-humanoid-control",children:"Transfer Learning for Humanoid Control"}),"\n",(0,r.jsx)(e.h3,{id:"reinforcement-learning-transfer",children:"Reinforcement Learning Transfer"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# Transfer learning for humanoid control policies\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\n\nclass HumanoidTransferLearner:\n    def __init__(self, sim_env, real_env):\n        self.sim_env = sim_env\n        self.real_env = real_env\n        self.sim_policy = None\n        self.real_policy = None\n\n    def train_sim_policy(self, policy_params=None):\n        """Train policy in simulation"""\n        if policy_params is None:\n            policy_params = {\n                \'learning_rate\': 3e-4,\n                \'n_steps\': 2048,\n                \'batch_size\': 64,\n                \'n_epochs\': 10,\n                \'gamma\': 0.99,\n                \'gae_lambda\': 0.95,\n                \'clip_range\': 0.2,\n                \'verbose\': 1\n            }\n\n        # Create vectorized environment for training\n        vec_env = make_vec_env(self.sim_env, n_envs=4)\n\n        # Initialize PPO agent\n        self.sim_policy = PPO(\n            "MlpPolicy",\n            vec_env,\n            **policy_params,\n            tensorboard_log="./logs/"\n        )\n\n        # Train the policy in simulation\n        self.sim_policy.learn(total_timesteps=100000)\n\n        return self.sim_policy\n\n    def transfer_to_real(self, real_timesteps=50000):\n        """Transfer policy from simulation to real with domain adaptation"""\n        if self.sim_policy is None:\n            raise ValueError("Simulation policy must be trained first")\n\n        # Initialize real environment\n        real_vec_env = make_vec_env(self.real_env, n_envs=1)\n\n        # Create new policy with same architecture\n        self.real_policy = PPO(\n            "MlpPolicy",\n            real_vec_env,\n            learning_rate=1e-5,  # Lower learning rate for fine-tuning\n            n_steps=512,\n            batch_size=32,\n            n_epochs=5,\n            gamma=0.99,\n            gae_lambda=0.95,\n            clip_range=0.1,  # Smaller clip range for stable fine-tuning\n            verbose=1\n        )\n\n        # Transfer weights from sim policy to real policy\n        self.real_policy.policy.load_state_dict(\n            self.sim_policy.policy.state_dict()\n        )\n\n        # Fine-tune on real environment\n        self.real_policy.learn(total_timesteps=real_timesteps)\n\n        return self.real_policy\n\n    def progressive_transfer(self, intermediate_envs=None):\n        """Progressively transfer through intermediate environments"""\n        if intermediate_envs is None:\n            intermediate_envs = self.create_intermediate_environments()\n\n        # Start with sim policy\n        current_policy = self.sim_policy\n\n        # Transfer through each intermediate environment\n        for i, env in enumerate(intermediate_envs):\n            print(f"Transferring to intermediate environment {i+1}")\n\n            # Create environment\n            vec_env = make_vec_env(env, n_envs=2)\n\n            # Create new policy\n            new_policy = PPO(\n                "MlpPolicy",\n                vec_env,\n                learning_rate=1e-4,\n                n_steps=1024,\n                batch_size=32,\n                n_epochs=5,\n                verbose=0\n            )\n\n            # Transfer weights\n            new_policy.policy.load_state_dict(\n                current_policy.policy.state_dict()\n            )\n\n            # Train on intermediate environment\n            new_policy.learn(total_timesteps=25000)\n\n            # Update current policy\n            current_policy = new_policy\n\n        # Finally transfer to real environment\n        real_vec_env = make_vec_env(self.real_env, n_envs=1)\n        self.real_policy = PPO(\n            "MlpPolicy",\n            real_vec_env,\n            learning_rate=5e-6,  # Very low learning rate for final transfer\n            n_steps=512,\n            batch_size=16,\n            n_epochs=3,\n            verbose=1\n        )\n\n        self.real_policy.policy.load_state_dict(\n            current_policy.policy.state_dict()\n        )\n\n        self.real_policy.learn(total_timesteps=25000)\n\n        return self.real_policy\n\n    def create_intermediate_environments(self):\n        """Create environments with gradually increasing reality gap"""\n        # This would create a series of environments with increasing\n        # realism, such as:\n        # 1. Simulation with added noise\n        # 2. Simulation with simplified dynamics\n        # 3. Simulation with realistic sensors\n        # 4. Physical setup with simplified tasks\n        # 5. Real environment\n        pass\n'})}),"\n",(0,r.jsx)(e.p,{children:"[@tobin2017; @peng2018]"}),"\n",(0,r.jsx)(e.h2,{id:"best-practices-for-sim-to-real-transfer",children:"Best Practices for Sim-to-Real Transfer"}),"\n",(0,r.jsx)(e.h3,{id:"systematic-approach",children:"Systematic Approach"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Start Simple"}),": Begin with basic tasks and gradually increase complexity"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Validate Simulation"}),": Ensure simulation accurately models real-world physics"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Use Domain Randomization"}),": Train on diverse simulation conditions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Collect Real Data"}),": Gather real-world data for validation and fine-tuning"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Iterative Refinement"}),": Continuously improve simulation fidelity based on real-world performance"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"common-pitfalls-to-avoid",children:"Common Pitfalls to Avoid"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Overfitting to specific simulation conditions"}),"\n",(0,r.jsx)(e.li,{children:"Ignoring sensor noise and latency differences"}),"\n",(0,r.jsx)(e.li,{children:"Neglecting actuator limitations and dynamics"}),"\n",(0,r.jsx)(e.li,{children:"Failing to validate simulation assumptions"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"research-tasks",children:"Research Tasks"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Investigate the impact of different domain randomization strategies on sim-to-real transfer success rates for humanoid locomotion"}),"\n",(0,r.jsx)(e.li,{children:"Explore the use of adversarial training techniques to improve domain adaptation"}),"\n",(0,r.jsx)(e.li,{children:"Analyze the relationship between simulation fidelity and transfer performance for different humanoid tasks"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"evidence-requirements",children:"Evidence Requirements"}),"\n",(0,r.jsx)(e.p,{children:"Students must demonstrate understanding by:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Implementing domain randomization in an Isaac Sim environment"}),"\n",(0,r.jsx)(e.li,{children:"Training a policy in simulation and validating its performance on real hardware (or realistic simulation)"}),"\n",(0,r.jsx)(e.li,{children:"Measuring and reporting the performance gap between simulation and reality"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["Peng, X. B., et al. (2018). Sim-to-real transfer of robotic control with dynamics randomization. ",(0,r.jsx)(e.em,{children:"2018 IEEE International Conference on Robotics and Automation (ICRA)"}),", 1-8."]}),"\n",(0,r.jsxs)(e.li,{children:["Tobin, J., et al. (2017). Domain randomization for transferring deep neural networks from simulation to the real world. ",(0,r.jsx)(e.em,{children:"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"}),", 23-30."]}),"\n",(0,r.jsxs)(e.li,{children:["Lakshmanan, K., et al. (2021). Accelerating reinforcement learning with domain randomization. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2105.02343"}),"."]}),"\n",(0,r.jsxs)(e.li,{children:["Michel, H., et al. (2018). Learning to navigate using synthetic data. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:1804.02713"}),"."]}),"\n",(0,r.jsxs)(e.li,{children:["Ganin, Y., et al. (2016). Domain-adversarial training of neural networks. ",(0,r.jsx)(e.em,{children:"Journal of Machine Learning Research"}),", 17(1), 2096-2030."]}),"\n",(0,r.jsxs)(e.li,{children:["Tzeng, E., et al. (2017). Adversarial discriminative domain adaptation. ",(0,r.jsx)(e.em,{children:"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"}),", 2962-2971."]}),"\n",(0,r.jsxs)(e.li,{children:["Yosinski, J., et al. (2014). How transferable are features in deep neural networks? ",(0,r.jsx)(e.em,{children:"Advances in Neural Information Processing Systems"}),", 27, 3320-3328."]}),"\n",(0,r.jsxs)(e.li,{children:["Donahue, J., et al. (2014). DeCAF: A deep convolutional activation feature for generic visual recognition. ",(0,r.jsx)(e.em,{children:"International Conference on Machine Learning"}),", 647-655."]}),"\n",(0,r.jsxs)(e.li,{children:["Koenemann, J., et al. (2015). Physics-based simulation and optimal control of humanoid robot systems. ",(0,r.jsx)(e.em,{children:"IEEE Transactions on Robotics"}),", 31(3), 658-670."]}),"\n",(0,r.jsxs)(e.li,{children:["Sadeghi, F., & Levine, S. (2017). CAD2RL: Real single-image flight without a single real image. ",(0,r.jsx)(e.em,{children:"2017 IEEE International Conference on Robotics and Automation (ICRA)"}),", 1991-1998."]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"practical-exercises",children:"Practical Exercises"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Implement visual domain randomization in Isaac Sim for a humanoid perception task"}),"\n",(0,r.jsx)(e.li,{children:"Train a humanoid locomotion policy in simulation and measure its performance degradation when applied to a more realistic simulation"}),"\n",(0,r.jsx)(e.li,{children:"Apply fine-tuning techniques to adapt a simulation-trained model to real-world data"}),"\n",(0,r.jsx)(e.li,{children:"Create a progressive transfer pipeline that gradually adapts models from simple simulation to complex real-world scenarios"}),"\n",(0,r.jsx)(e.li,{children:"Implement and compare different domain adaptation techniques for transferring perception models to real humanoid robots"}),"\n",(0,r.jsx)(e.li,{children:"Design and test a validation framework to measure the fidelity between simulation and real-world performance"}),"\n",(0,r.jsx)(e.li,{children:"Build a complete sim-to-real transfer pipeline for a specific humanoid task (e.g., object manipulation or navigation)"}),"\n"]})]})}function c(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(m,{...n})}):m(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>t,x:()=>o});var i=a(6540);const r={},s=i.createContext(r);function t(n){const e=i.useContext(s);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:t(n.components),i.createElement(s.Provider,{value:e},n.children)}}}]);