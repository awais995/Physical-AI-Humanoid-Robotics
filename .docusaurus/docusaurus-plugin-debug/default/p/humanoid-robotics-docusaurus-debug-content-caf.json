{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/humanoid-robotics/docs","tagsPath":"/humanoid-robotics/docs/tags","editUrl":"https://github.com/your-username/your-project-name/tree/main/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"D:\\Web 3 Metavers and GenAI\\Wasif\\Bhaijan Hackathon\\humanoid-robotics\\sidebars.js","contentPath":"D:\\Web 3 Metavers and GenAI\\Wasif\\Bhaijan Hackathon\\humanoid-robotics\\docs","docs":[{"id":"index","title":"Physical AI & Humanoid Robotics","description":"This comprehensive guide covers the essential concepts and practical implementations for developing humanoid robots with artificial intelligence capabilities.","source":"@site/docs/index.md","sourceDirName":".","slug":"/","permalink":"/humanoid-robotics/docs/","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/index.md","tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0}},{"id":"intro","title":"Physical AI & Humanoid Robotics: A Comprehensive Guide","description":"Welcome to the Future of Robotics","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/humanoid-robotics/docs/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","next":{"title":"Module 1: ROS 2 (Robotic Nervous System)","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/"}},{"id":"module1/ROS-2-Robotic-Nervous-System/chapter1-nodes-topics-services","title":"Chapter 1: Nodes, Topics, and Services","description":"This chapter covers the fundamental communication patterns in ROS 2: nodes, topics, and services that form the backbone of robotic systems.","source":"@site/docs/module1/ROS-2-Robotic-Nervous-System/chapter1-nodes-topics-services.md","sourceDirName":"module1/ROS-2-Robotic-Nervous-System","slug":"/module1/ROS-2-Robotic-Nervous-System/chapter1-nodes-topics-services","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/chapter1-nodes-topics-services","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module1/ROS-2-Robotic-Nervous-System/chapter1-nodes-topics-services.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Module 1: ROS 2 (Robotic Nervous System)","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/"},"next":{"title":"Chapter 2: rclpy Integration","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/chapter2-rclpy-integration"}},{"id":"module1/ROS-2-Robotic-Nervous-System/chapter2-rclpy-integration","title":"Chapter 2: rclpy Integration","description":"This chapter covers the Python client library for ROS 2 (rclpy) and how to integrate it with humanoid robotics applications.","source":"@site/docs/module1/ROS-2-Robotic-Nervous-System/chapter2-rclpy-integration.md","sourceDirName":"module1/ROS-2-Robotic-Nervous-System","slug":"/module1/ROS-2-Robotic-Nervous-System/chapter2-rclpy-integration","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/chapter2-rclpy-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module1/ROS-2-Robotic-Nervous-System/chapter2-rclpy-integration.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Nodes, Topics, and Services","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/chapter1-nodes-topics-services"},"next":{"title":"Chapter 3: URDF for Humanoids","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/chapter3-urdf-humanoids"}},{"id":"module1/ROS-2-Robotic-Nervous-System/chapter3-urdf-humanoids","title":"Chapter 3: URDF for Humanoids","description":"This chapter covers the Unified Robot Description Format (URDF) and its application to humanoid robot modeling in ROS 2.","source":"@site/docs/module1/ROS-2-Robotic-Nervous-System/chapter3-urdf-humanoids.md","sourceDirName":"module1/ROS-2-Robotic-Nervous-System","slug":"/module1/ROS-2-Robotic-Nervous-System/chapter3-urdf-humanoids","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/chapter3-urdf-humanoids","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module1/ROS-2-Robotic-Nervous-System/chapter3-urdf-humanoids.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: rclpy Integration","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/chapter2-rclpy-integration"},"next":{"title":"Module 2: Digital Twin (Gazebo + Unity)","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/"}},{"id":"module1/ROS-2-Robotic-Nervous-System/citations-validation","title":"ROS 2 Citation Validation","description":"This document validates citations for the ROS 2 module content to ensure compliance with constitutional standards for academic rigor.","source":"@site/docs/module1/ROS-2-Robotic-Nervous-System/citations-validation.md","sourceDirName":"module1/ROS-2-Robotic-Nervous-System","slug":"/module1/ROS-2-Robotic-Nervous-System/citations-validation","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/citations-validation","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module1/ROS-2-Robotic-Nervous-System/citations-validation.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2}},{"id":"module1/ROS-2-Robotic-Nervous-System/index","title":"Module 1: ROS 2 (Robotic Nervous System)","description":"This module covers the fundamentals of ROS 2 as the nervous system of robots, including nodes, topics, services, actions, and how to integrate rclpy agents with humanoid URDF models.","source":"@site/docs/module1/ROS-2-Robotic-Nervous-System/index.md","sourceDirName":"module1/ROS-2-Robotic-Nervous-System","slug":"/module1/ROS-2-Robotic-Nervous-System/","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module1/ROS-2-Robotic-Nervous-System/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Physical AI & Humanoid Robotics: A Comprehensive Guide","permalink":"/humanoid-robotics/docs/intro"},"next":{"title":"Chapter 1: Nodes, Topics, and Services","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/chapter1-nodes-topics-services"}},{"id":"module1/ROS-2-Robotic-Nervous-System/plagiarism-check","title":"ROS 2 Plagiarism Check","description":"This document ensures 0% plagiarism for the ROS 2 module content as required by constitutional standards.","source":"@site/docs/module1/ROS-2-Robotic-Nervous-System/plagiarism-check.md","sourceDirName":"module1/ROS-2-Robotic-Nervous-System","slug":"/module1/ROS-2-Robotic-Nervous-System/plagiarism-check","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/plagiarism-check","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module1/ROS-2-Robotic-Nervous-System/plagiarism-check.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3}},{"id":"module2/Digital-Twin-Gazebo-Unity/chapter1-gazebo-unity","title":"Chapter 1: Gazebo and Unity Integration","description":"This chapter covers the integration of Gazebo and Unity for creating comprehensive digital twin environments for humanoid robotics applications.","source":"@site/docs/module2/Digital-Twin-Gazebo-Unity/chapter1-gazebo-unity.md","sourceDirName":"module2/Digital-Twin-Gazebo-Unity","slug":"/module2/Digital-Twin-Gazebo-Unity/chapter1-gazebo-unity","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/chapter1-gazebo-unity","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module2/Digital-Twin-Gazebo-Unity/chapter1-gazebo-unity.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Module 2: Digital Twin (Gazebo + Unity)","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/"},"next":{"title":"Chapter 2: Physics Simulation and Collisions","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/chapter2-physics-simulation"}},{"id":"module2/Digital-Twin-Gazebo-Unity/chapter2-physics-simulation","title":"Chapter 2: Physics Simulation and Collisions","description":"This chapter covers the implementation of physics simulation and collision detection for humanoid robots in digital twin environments.","source":"@site/docs/module2/Digital-Twin-Gazebo-Unity/chapter2-physics-simulation.md","sourceDirName":"module2/Digital-Twin-Gazebo-Unity","slug":"/module2/Digital-Twin-Gazebo-Unity/chapter2-physics-simulation","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/chapter2-physics-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module2/Digital-Twin-Gazebo-Unity/chapter2-physics-simulation.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Gazebo and Unity Integration","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/chapter1-gazebo-unity"},"next":{"title":"Chapter 3: Sensor Simulation","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/chapter3-sensors-simulation"}},{"id":"module2/Digital-Twin-Gazebo-Unity/chapter3-sensors-simulation","title":"Chapter 3: Sensor Simulation","description":"This chapter covers the implementation and simulation of various sensors for humanoid robots, including LiDAR, depth cameras, and IMUs in digital twin environments.","source":"@site/docs/module2/Digital-Twin-Gazebo-Unity/chapter3-sensors-simulation.md","sourceDirName":"module2/Digital-Twin-Gazebo-Unity","slug":"/module2/Digital-Twin-Gazebo-Unity/chapter3-sensors-simulation","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/chapter3-sensors-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module2/Digital-Twin-Gazebo-Unity/chapter3-sensors-simulation.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Physics Simulation and Collisions","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/chapter2-physics-simulation"},"next":{"title":"Module 3: NVIDIA Isaac (AI-Robot Brain)","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/"}},{"id":"module2/Digital-Twin-Gazebo-Unity/citations-validation","title":"Digital Twin Citation Validation","description":"This document validates citations for the Digital Twin module content to ensure compliance with constitutional standards for academic rigor.","source":"@site/docs/module2/Digital-Twin-Gazebo-Unity/citations-validation.md","sourceDirName":"module2/Digital-Twin-Gazebo-Unity","slug":"/module2/Digital-Twin-Gazebo-Unity/citations-validation","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/citations-validation","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module2/Digital-Twin-Gazebo-Unity/citations-validation.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2}},{"id":"module2/Digital-Twin-Gazebo-Unity/index","title":"Module 2: Digital Twin (Gazebo + Unity)","description":"This module covers creating and working with digital twin environments using Gazebo and Unity, including physics simulation, sensor modeling, and high-fidelity rendering for humanoid robotics applications.","source":"@site/docs/module2/Digital-Twin-Gazebo-Unity/index.md","sourceDirName":"module2/Digital-Twin-Gazebo-Unity","slug":"/module2/Digital-Twin-Gazebo-Unity/","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module2/Digital-Twin-Gazebo-Unity/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: URDF for Humanoids","permalink":"/humanoid-robotics/docs/module1/ROS-2-Robotic-Nervous-System/chapter3-urdf-humanoids"},"next":{"title":"Chapter 1: Gazebo and Unity Integration","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/chapter1-gazebo-unity"}},{"id":"module2/Digital-Twin-Gazebo-Unity/plagiarism-check","title":"Digital Twin Plagiarism Check","description":"This document ensures 0% plagiarism for the Digital Twin module content as required by constitutional standards.","source":"@site/docs/module2/Digital-Twin-Gazebo-Unity/plagiarism-check.md","sourceDirName":"module2/Digital-Twin-Gazebo-Unity","slug":"/module2/Digital-Twin-Gazebo-Unity/plagiarism-check","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/plagiarism-check","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module2/Digital-Twin-Gazebo-Unity/plagiarism-check.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3}},{"id":"module3/NVIDIA-Isaac-AI-Robot-Brain/chapter1-isaac-sim","title":"Chapter 1: Isaac Sim and Synthetic Data","description":"This chapter covers NVIDIA Isaac Sim for generating synthetic data to train perception models for humanoid robots.","source":"@site/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter1-isaac-sim.md","sourceDirName":"module3/NVIDIA-Isaac-AI-Robot-Brain","slug":"/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter1-isaac-sim","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter1-isaac-sim","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter1-isaac-sim.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Module 3: NVIDIA Isaac (AI-Robot Brain)","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/"},"next":{"title":"Chapter 2: VSLAM and Navigation","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter2-vslam-navigation"}},{"id":"module3/NVIDIA-Isaac-AI-Robot-Brain/chapter2-vslam-navigation","title":"Chapter 2: VSLAM and Navigation","description":"This chapter covers Visual Simultaneous Localization and Mapping (VSLAM) and navigation using NVIDIA Isaac ROS components for humanoid robots.","source":"@site/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter2-vslam-navigation.md","sourceDirName":"module3/NVIDIA-Isaac-AI-Robot-Brain","slug":"/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter2-vslam-navigation","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter2-vslam-navigation","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter2-vslam-navigation.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Isaac Sim and Synthetic Data","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter1-isaac-sim"},"next":{"title":"Chapter 3: Nav2 for Bipedal Path Planning","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter3-nav2-bipedal"}},{"id":"module3/NVIDIA-Isaac-AI-Robot-Brain/chapter3-nav2-bipedal","title":"Chapter 3: Nav2 for Bipedal Path Planning","description":"This chapter covers configuring and using the Navigation2 stack specifically for bipedal humanoid robot path planning and navigation.","source":"@site/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter3-nav2-bipedal.md","sourceDirName":"module3/NVIDIA-Isaac-AI-Robot-Brain","slug":"/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter3-nav2-bipedal","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter3-nav2-bipedal","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter3-nav2-bipedal.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: VSLAM and Navigation","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter2-vslam-navigation"},"next":{"title":"Chapter 4: Sim-to-Real Transfer","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real"}},{"id":"module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real","title":"Chapter 4: Sim-to-Real Transfer","description":"This chapter covers the techniques and methodologies for transferring models and behaviors trained in simulation to real-world humanoid robots using NVIDIA Isaac platforms.","source":"@site/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real.md","sourceDirName":"module3/NVIDIA-Isaac-AI-Robot-Brain","slug":"/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Nav2 for Bipedal Path Planning","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter3-nav2-bipedal"},"next":{"title":"Module 4: Vision-Language-Action (VLA) + Capstone","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/"}},{"id":"module3/NVIDIA-Isaac-AI-Robot-Brain/citations-validation","title":"NVIDIA Isaac Citation Validation","description":"This document validates citations for the NVIDIA Isaac module content to ensure compliance with constitutional standards for academic rigor.","source":"@site/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/citations-validation.md","sourceDirName":"module3/NVIDIA-Isaac-AI-Robot-Brain","slug":"/module3/NVIDIA-Isaac-AI-Robot-Brain/citations-validation","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/citations-validation","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/citations-validation.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2}},{"id":"module3/NVIDIA-Isaac-AI-Robot-Brain/index","title":"Module 3: NVIDIA Isaac (AI-Robot Brain)","description":"This module covers using NVIDIA Isaac for AI-powered robotics, including Isaac Sim for synthetic data generation, Isaac ROS for perception and navigation, and Nav2 for path planning.","source":"@site/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/index.md","sourceDirName":"module3/NVIDIA-Isaac-AI-Robot-Brain","slug":"/module3/NVIDIA-Isaac-AI-Robot-Brain/","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Sensor Simulation","permalink":"/humanoid-robotics/docs/module2/Digital-Twin-Gazebo-Unity/chapter3-sensors-simulation"},"next":{"title":"Chapter 1: Isaac Sim and Synthetic Data","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter1-isaac-sim"}},{"id":"module3/NVIDIA-Isaac-AI-Robot-Brain/plagiarism-check","title":"NVIDIA Isaac Plagiarism Check","description":"This document ensures 0% plagiarism for the NVIDIA Isaac module content as required by constitutional standards.","source":"@site/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/plagiarism-check.md","sourceDirName":"module3/NVIDIA-Isaac-AI-Robot-Brain","slug":"/module3/NVIDIA-Isaac-AI-Robot-Brain/plagiarism-check","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/plagiarism-check","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/plagiarism-check.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3}},{"id":"module4/Vision-Language-Action-VLA/chapter1-whisper-commands","title":"Chapter 1: Whisper Voice Commands","description":"This chapter covers implementing voice-activated robotics systems using OpenAI's Whisper for voice command recognition in humanoid robots.","source":"@site/docs/module4/Vision-Language-Action-VLA/chapter1-whisper-commands.md","sourceDirName":"module4/Vision-Language-Action-VLA","slug":"/module4/Vision-Language-Action-VLA/chapter1-whisper-commands","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter1-whisper-commands","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module4/Vision-Language-Action-VLA/chapter1-whisper-commands.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Module 4: Vision-Language-Action (VLA) + Capstone","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/"},"next":{"title":"Chapter 2: LLM-based Cognitive Planning","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter2-llm-planning"}},{"id":"module4/Vision-Language-Action-VLA/chapter2-llm-planning","title":"Chapter 2: LLM-based Cognitive Planning","description":"This chapter covers implementing cognitive planning systems for humanoid robots using Large Language Models (LLMs) to process voice commands and generate executable action plans.","source":"@site/docs/module4/Vision-Language-Action-VLA/chapter2-llm-planning.md","sourceDirName":"module4/Vision-Language-Action-VLA","slug":"/module4/Vision-Language-Action-VLA/chapter2-llm-planning","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter2-llm-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module4/Vision-Language-Action-VLA/chapter2-llm-planning.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Whisper Voice Commands","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter1-whisper-commands"},"next":{"title":"Chapter 3: Voice-to-Action Pipelines","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter3-voice-to-action"}},{"id":"module4/Vision-Language-Action-VLA/chapter3-voice-to-action","title":"Chapter 3: Voice-to-Action Pipelines","description":"This chapter covers the implementation of voice-to-action pipelines that convert spoken commands into executable robotic behaviors, integrating speech recognition, natural language processing, and action execution systems.","source":"@site/docs/module4/Vision-Language-Action-VLA/chapter3-voice-to-action.md","sourceDirName":"module4/Vision-Language-Action-VLA","slug":"/module4/Vision-Language-Action-VLA/chapter3-voice-to-action","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter3-voice-to-action","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module4/Vision-Language-Action-VLA/chapter3-voice-to-action.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: LLM-based Cognitive Planning","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter2-llm-planning"},"next":{"title":"Plagiarism Check for Capstone Integration Content","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter4-capstone-plagiarism-check"}},{"id":"module4/Vision-Language-Action-VLA/chapter4-capstone-plagiarism-check","title":"Plagiarism Check for Capstone Integration Content","description":"This document ensures that all capstone integration content in the Vision-Language-Action module is original and properly attributed to meet constitutional requirements for academic integrity.","source":"@site/docs/module4/Vision-Language-Action-VLA/chapter4-capstone-plagiarism-check.md","sourceDirName":"module4/Vision-Language-Action-VLA","slug":"/module4/Vision-Language-Action-VLA/chapter4-capstone-plagiarism-check","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter4-capstone-plagiarism-check","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module4/Vision-Language-Action-VLA/chapter4-capstone-plagiarism-check.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Voice-to-Action Pipelines","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter3-voice-to-action"},"next":{"title":"References and Citations","permalink":"/humanoid-robotics/docs/references/citations"}},{"id":"module4/Vision-Language-Action-VLA/citations-validation","title":"Citation Validation for Vision-Language-Action (VLA) Module","description":"This document validates that all citations in the Vision-Language-Action module meet constitutional requirements for academic rigor and credibility.","source":"@site/docs/module4/Vision-Language-Action-VLA/citations-validation.md","sourceDirName":"module4/Vision-Language-Action-VLA","slug":"/module4/Vision-Language-Action-VLA/citations-validation","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/citations-validation","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module4/Vision-Language-Action-VLA/citations-validation.md","tags":[],"version":"current","frontMatter":{}},{"id":"module4/Vision-Language-Action-VLA/index","title":"Module 4: Vision-Language-Action (VLA) + Capstone","description":"This module covers implementing voice-activated robotics systems using Whisper for voice commands, LLMs for cognitive planning, and voice-to-action pipelines, plus the capstone integration project.","source":"@site/docs/module4/Vision-Language-Action-VLA/index.md","sourceDirName":"module4/Vision-Language-Action-VLA","slug":"/module4/Vision-Language-Action-VLA/","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module4/Vision-Language-Action-VLA/index.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Sim-to-Real Transfer","permalink":"/humanoid-robotics/docs/module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real"},"next":{"title":"Chapter 1: Whisper Voice Commands","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter1-whisper-commands"}},{"id":"module4/Vision-Language-Action-VLA/plagiarism-check","title":"Plagiarism Check for Vision-Language-Action (VLA) Module","description":"This document ensures that all content in the Vision-Language-Action module is original and properly attributed to meet constitutional requirements for academic integrity.","source":"@site/docs/module4/Vision-Language-Action-VLA/plagiarism-check.md","sourceDirName":"module4/Vision-Language-Action-VLA","slug":"/module4/Vision-Language-Action-VLA/plagiarism-check","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/plagiarism-check","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/module4/Vision-Language-Action-VLA/plagiarism-check.md","tags":[],"version":"current","frontMatter":{}},{"id":"references/citations","title":"References and Citations","description":"This document contains the comprehensive list of references used throughout the Physical AI & Humanoid Robotics book, following APA citation format as required by constitutional standards.","source":"@site/docs/references/citations.md","sourceDirName":"references","slug":"/references/citations","permalink":"/humanoid-robotics/docs/references/citations","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/references/citations.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Plagiarism Check for Capstone Integration Content","permalink":"/humanoid-robotics/docs/module4/Vision-Language-Action-VLA/chapter4-capstone-plagiarism-check"},"next":{"title":"Getting Started Tutorial","permalink":"/humanoid-robotics/docs/tutorials/getting-started"}},{"id":"tutorials/getting-started","title":"Getting Started Tutorial","description":"This tutorial provides a step-by-step introduction to the Physical AI & Humanoid Robotics book and helps you set up your development environment.","source":"@site/docs/tutorials/getting-started.md","sourceDirName":"tutorials","slug":"/tutorials/getting-started","permalink":"/humanoid-robotics/docs/tutorials/getting-started","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/docs/tutorials/getting-started.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"References and Citations","permalink":"/humanoid-robotics/docs/references/citations"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro"},{"type":"category","label":"Module 1: ROS 2 (Robotic Nervous System)","items":[{"type":"doc","id":"module1/ROS-2-Robotic-Nervous-System/index"},{"type":"doc","id":"module1/ROS-2-Robotic-Nervous-System/chapter1-nodes-topics-services"},{"type":"doc","id":"module1/ROS-2-Robotic-Nervous-System/chapter2-rclpy-integration"},{"type":"doc","id":"module1/ROS-2-Robotic-Nervous-System/chapter3-urdf-humanoids"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Digital Twin (Gazebo + Unity)","items":[{"type":"doc","id":"module2/Digital-Twin-Gazebo-Unity/index"},{"type":"doc","id":"module2/Digital-Twin-Gazebo-Unity/chapter1-gazebo-unity"},{"type":"doc","id":"module2/Digital-Twin-Gazebo-Unity/chapter2-physics-simulation"},{"type":"doc","id":"module2/Digital-Twin-Gazebo-Unity/chapter3-sensors-simulation"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: NVIDIA Isaac (AI-Robot Brain)","items":[{"type":"doc","id":"module3/NVIDIA-Isaac-AI-Robot-Brain/index"},{"type":"doc","id":"module3/NVIDIA-Isaac-AI-Robot-Brain/chapter1-isaac-sim"},{"type":"doc","id":"module3/NVIDIA-Isaac-AI-Robot-Brain/chapter2-vslam-navigation"},{"type":"doc","id":"module3/NVIDIA-Isaac-AI-Robot-Brain/chapter3-nav2-bipedal"},{"type":"doc","id":"module3/NVIDIA-Isaac-AI-Robot-Brain/chapter4-sim-to-real"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA) + Capstone","items":[{"type":"doc","id":"module4/Vision-Language-Action-VLA/index"},{"type":"doc","id":"module4/Vision-Language-Action-VLA/chapter1-whisper-commands"},{"type":"doc","id":"module4/Vision-Language-Action-VLA/chapter2-llm-planning"},{"type":"doc","id":"module4/Vision-Language-Action-VLA/chapter3-voice-to-action"},{"type":"doc","id":"module4/Vision-Language-Action-VLA/chapter4-capstone-plagiarism-check"}],"collapsed":true,"collapsible":true},{"type":"category","label":"References","items":[{"type":"doc","id":"references/citations"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Tutorials","items":[{"type":"doc","id":"tutorials/getting-started"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[],"blogListPaginated":[],"blogTags":{},"blogTagsListPath":"/humanoid-robotics/blog/tags"}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/humanoid-robotics/","source":"@site/src/pages/index.js"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}